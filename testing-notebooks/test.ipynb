{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- ablation keep list (paste from TensorBoard text) ----\n",
    "KEEP_CSV = \"dist_to_ball_norm,sin_to_ball,cos_to_ball,atk_team_1hot,def_team_1hot,att_glob_vx_norm,att_glob_vy_norm,def_glob_vx_norm,def_glob_vy_norm,gaussian_control,nearest_def_dist_norm,\" \\\n",
    "\"boundary_dist_norm,centerline_dist_norm,goal_sin,goal_cos,goal_dist_norm\"\n",
    "\n",
    "KEEP_NAMES = [s.strip() for s in KEEP_CSV.split(\",\") if s.strip()]\n",
    "\n",
    "# Static channel names MUST match PitchStaticChannels.forward() stacking order in your code\n",
    "STATIC_NAMES = [\"boundary_dist_norm\", \"centerline_dist_norm\", \"goal_sin\", \"goal_cos\", \"goal_dist_norm\"]\n",
    "STATIC_SET = set(STATIC_NAMES)\n",
    "\n",
    "def build_keep_indices(mm_channels: list[str], keep_names: list[str]):\n",
    "    dyn_name_to_idx = {n:i for i,n in enumerate(mm_channels)}\n",
    "    dyn_keep = []\n",
    "    static_keep = []\n",
    "    unknown = []\n",
    "\n",
    "    for n in keep_names:\n",
    "        if n in STATIC_SET:\n",
    "            static_keep.append(n)\n",
    "        elif n in dyn_name_to_idx:\n",
    "            dyn_keep.append(n)\n",
    "        else:\n",
    "            unknown.append(n)\n",
    "\n",
    "    if unknown:\n",
    "        raise ValueError(f\"Keep list contains unknown channels not in manifest or static set: {unknown}\")\n",
    "\n",
    "    dyn_keep_idxs = [dyn_name_to_idx[n] for n in dyn_keep]\n",
    "    static_keep_idxs = [STATIC_NAMES.index(n) for n in static_keep]\n",
    "    return dyn_keep, dyn_keep_idxs, static_keep, static_keep_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "os.chdir('..')\n",
    "\n",
    "from utils.visualizer import SoccerVisualizer  # same import style as eval-viz.py\n",
    "from utils.train_utils import * \n",
    "# --- memmap helpers (adapted from eval-viz.py) ---\n",
    "class MemmapShard:\n",
    "    def __init__(self, root_dir: str, x_name: str, t_name: str, n: int, C: int, H: int, W: int):\n",
    "        self.n = int(n)\n",
    "        self.C, self.H, self.W = int(C), int(H), int(W)\n",
    "        self.X = np.memmap(os.path.join(root_dir, x_name), mode=\"r\", dtype=np.float16,\n",
    "                           shape=(self.n, self.C, self.H, self.W))\n",
    "        self.T = np.memmap(os.path.join(root_dir, t_name), mode=\"r\", dtype=np.float32,\n",
    "                           shape=(self.n, 3))\n",
    "\n",
    "class MemmapManifest:\n",
    "    def __init__(self, root_dir: str, cache_size: int = 2):\n",
    "        self.root_dir = root_dir\n",
    "        self.cache_size = int(cache_size)\n",
    "\n",
    "        with open(os.path.join(root_dir, \"manifest.json\"), \"r\") as f:\n",
    "            man = json.load(f)\n",
    "        assert man.get(\"format\") == \"memmap_v1\"\n",
    "\n",
    "        self.C = int(man[\"C\"]); self.H = int(man[\"H\"]); self.W = int(man[\"W\"])\n",
    "        self.channels = list(man.get(\"channels\", []))\n",
    "        self.shards = list(man[\"shards\"])\n",
    "\n",
    "        self.starts = []\n",
    "        cur = 0\n",
    "        for s in self.shards:\n",
    "            self.starts.append(cur)\n",
    "            cur += int(s[\"n\"])\n",
    "        self.total = cur\n",
    "\n",
    "        self._cache = OrderedDict()\n",
    "\n",
    "    def _open_shard(self, shard_id: int) -> MemmapShard:\n",
    "        shard_id = int(shard_id)\n",
    "        if shard_id in self._cache:\n",
    "            self._cache.move_to_end(shard_id)\n",
    "            return self._cache[shard_id]\n",
    "        s = self.shards[shard_id]\n",
    "        mm = MemmapShard(self.root_dir, s[\"x_path\"], s[\"t_path\"], int(s[\"n\"]), self.C, self.H, self.W)\n",
    "        self._cache[shard_id] = mm\n",
    "        if len(self._cache) > self.cache_size:\n",
    "            self._cache.popitem(last=False)\n",
    "        return mm\n",
    "\n",
    "    def locate(self, k: int):\n",
    "        k = int(k)\n",
    "        lo, hi = 0, len(self.starts) - 1\n",
    "        while lo <= hi:\n",
    "            mid = (lo + hi) // 2\n",
    "            start = self.starts[mid]\n",
    "            end = self.starts[mid + 1] if mid + 1 < len(self.starts) else self.total\n",
    "            if start <= k < end:\n",
    "                return mid, k - start\n",
    "            if k < start: hi = mid - 1\n",
    "            else: lo = mid + 1\n",
    "        raise RuntimeError(\"locate failed\")\n",
    "\n",
    "    def load_by_shard_local(self, shard_id: int, local_i: int, swap_xy: bool = False):\n",
    "        shard = self._open_shard(shard_id)\n",
    "        x = torch.from_numpy(np.array(shard.X[local_i], copy=True)).float()  # (C,H,W)\n",
    "        t = shard.T[local_i]\n",
    "        dst_xy = torch.tensor(t[:2], dtype=torch.long)\n",
    "        if swap_xy:\n",
    "            dst_xy = dst_xy[[1, 0]]\n",
    "        y = torch.tensor(float(t[2]), dtype=torch.float32)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        y = torch.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return x, dst_xy, y\n",
    "\n",
    "# ---- choose dataset + load manifest once ----\n",
    "DATA_ROOT = \"data/finaldata-3meter\"  # has train/ and val/\n",
    "SPLIT = \"val\"                                # \"train\" or \"val\"\n",
    "mm = MemmapManifest(os.path.join(DATA_ROOT, SPLIT), cache_size=2)\n",
    "print(f\"[data] split={SPLIT} N={mm.total} C,H,W={mm.C},{mm.H},{mm.W}\")\n",
    "\n",
    "\n",
    "# ---- shard selection ----\n",
    "# You can lock to a specific shard_id to avoid re-opening new ones:\n",
    "SHARD_ID = None  # set to int to force a specific shard\n",
    "if SHARD_ID is None:\n",
    "    SHARD_ID = int(np.random.randint(0, len(mm.shards)))\n",
    "shard_n = int(mm.shards[SHARD_ID][\"n\"])\n",
    "print(f\"[data] using shard_id={SHARD_ID} n={shard_n}\")\n",
    "\n",
    "def sample_from_loaded_shard(local_i=None, swap_xy=False):\n",
    "    if local_i is None:\n",
    "        local_i = int(np.random.randint(0, shard_n))\n",
    "    x_chw, dst_xy, y = mm.load_by_shard_local(SHARD_ID, local_i, swap_xy=swap_xy)\n",
    "    return local_i, x_chw, dst_xy, y\n",
    "\n",
    "dyn_keep_names, dyn_keep_idxs, static_keep_names, static_keep_idxs = build_keep_indices(mm.channels, KEEP_NAMES)\n",
    "\n",
    "print(\"[ablation] dyn keep:\", dyn_keep_names)\n",
    "print(\"[ablation] static keep:\", static_keep_names)\n",
    "print(\"[ablation] dyn_keep_idxs:\", dyn_keep_idxs)\n",
    "print(\"[ablation] static_keep_idxs:\", static_keep_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d878964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.static_maps import PitchStaticChannels, PitchDims\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- static channels (same as training) ---\n",
    "static = PitchStaticChannels(dims=PitchDims(H=mm.H, W=mm.W)).to(DEVICE)\n",
    "\n",
    "# infer full static count (from PitchStaticChannels)\n",
    "with torch.no_grad():\n",
    "    C_static_full = int(static.forward().shape[0])\n",
    "\n",
    "# Effective channels after ablation slicing\n",
    "C_dyn_eff = len(dyn_keep_idxs)\n",
    "C_static_eff = len(static_keep_idxs)\n",
    "IN_CHANNELS = C_dyn_eff + C_static_eff\n",
    "\n",
    "print(f\"[static] C_dyn_full={mm.C} C_static_full={C_static_full}\")\n",
    "print(f\"[static] C_dyn_eff={C_dyn_eff} C_static_eff={C_static_eff} -> in_channels={IN_CHANNELS}\")\n",
    "\n",
    "\n",
    "# --- model (replace with your actual constructor) ---\n",
    "from models.footballmap import PassMap\n",
    "#model = BetterSoccerMap2Head(in_channels=IN_CHANNELS, base=64, blocks_per_stage=2, dropout=0.0).to(DEVICE).float()\n",
    "model = PassMap(in_channels=IN_CHANNELS, base=64, blocks_per_stage=4).to(DEVICE).float()\n",
    "#model =  PitchVisionNet(C_dyn+C_static, base=64, blocks_per_stage=3).to(DEVICE).float()\n",
    "# --- checkpoint loading (adapt to your ckpt format) ---\n",
    "CKPT_PATH = \"overnight-training-runs/20251217-015059_PassMap_drop_ball_vel/best_ckpt.pt\"\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE,weights_only= False)\n",
    "# common patterns:\n",
    "if isinstance(ckpt, dict) and \"model_state\" in ckpt:\n",
    "    sd = ckpt[\"model_state\"]\n",
    "elif isinstance(ckpt, dict) and \"model\" in ckpt:\n",
    "    sd = ckpt[\"model\"]\n",
    "elif isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "    sd = ckpt[\"state_dict\"]\n",
    "else:\n",
    "    sd = ckpt\n",
    "\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(f\"[ckpt] loaded {CKPT_PATH}\")\n",
    "if missing: print(f\"[warn] missing keys: {len(missing)}\")\n",
    "if unexpected: print(f\"[warn] unexpected keys: {len(unexpected)}\")\n",
    "\n",
    "print(ckpt['args'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d47e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_twohead_maps(out: dict):\n",
    "    dest = out[\"dest_logits\"]  # (B,1,H,W) or (B,H,W)\n",
    "    succ = out[\"succ_logits\"]\n",
    "\n",
    "    if dest.dim() == 4: dest = dest[:, 0]\n",
    "    if succ.dim() == 4: succ = succ[:, 0]\n",
    "    \n",
    "\n",
    "    B, H, W = dest.shape\n",
    "    dest_probs = torch.softmax(dest.view(B, -1), dim=1).view(B, H, W)\n",
    "    succ_probs = torch.sigmoid(succ)\n",
    "    comp_map = dest_probs * succ_probs\n",
    "    return dest_probs[0], succ_probs[0], comp_map[0]\n",
    "\n",
    "def infer_and_plot(local_i=None, swap_xy=False, coords_are_centers=False):\n",
    "    local_i, x_chw, dst_xy, y = sample_from_loaded_shard(local_i=local_i, swap_xy=swap_xy)\n",
    "\n",
    "    # append static channels (B,C,*,*) -> (B,C+Cstatic,*,*)\n",
    "    X = x_chw.unsqueeze(0).to(DEVICE)\n",
    "    X = static.concat_to(X, dim=1)\n",
    "    X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "        dest_map, succ_map, comp_map = compute_twohead_maps(out)\n",
    "\n",
    "    # destination marker coords\n",
    "    dst_x = float(dst_xy[0].item())\n",
    "    dst_y = float(dst_xy[1].item())\n",
    "    if not coords_are_centers:\n",
    "        dst_x += 0.5\n",
    "        dst_y += 0.5\n",
    "\n",
    "    # start location from dist_to_ball argmin (channel 0 in your current schema)\n",
    "    ball_dist = x_chw[0]\n",
    "    flat_idx = torch.argmin(ball_dist)\n",
    "    x_idx = (flat_idx // ball_dist.shape[1]).item()\n",
    "    y_idx = (flat_idx %  ball_dist.shape[1]).item()\n",
    "    bx, by = float(x_idx) + 0.5, float(y_idx) + 0.5\n",
    "\n",
    "    # occupancy maps for overlay (channel 3/4 in your current schema)\n",
    "    in_pos  = (x_chw[3] > 0).float()\n",
    "    out_pos = (x_chw[4] > 0).float()\n",
    "\n",
    "    vis = SoccerVisualizer(pitch_length=mm.H, pitch_width=mm.W, layout=\"x_rows\")\n",
    "\n",
    "    ok = \"✓\" if int(y.item()) == 1 else \"✗\"\n",
    "\n",
    "    def _plot(heat_t: torch.Tensor, title: str):\n",
    "        fig, ax, _ = vis.plot_state(\n",
    "            in_possession=in_pos,\n",
    "            out_possession=out_pos,\n",
    "            heatmap=heat_t.detach().cpu(),\n",
    "            cmap=\"Blues\",\n",
    "            heatmap_kwargs=dict(alpha=0.9),\n",
    "            add_colorbar=True,\n",
    "        )\n",
    "        ax.scatter([bx], [by], c=\"black\", s=30, marker=\"o\", zorder=6, linewidths=0.5, label=\"Start\")\n",
    "        ax.scatter([dst_x], [dst_y], c=\"red\",   s=30, marker=\"o\", zorder=6, linewidths=0.5, label=\"End\")\n",
    "        ax.set_title(title)\n",
    "        fig.tight_layout()\n",
    "        fig.legend()\n",
    "\n",
    "    _plot(dest_map, f\"Destination P(dest=cell | s) | pass {ok} | local_i={local_i}\")\n",
    "    _plot(succ_map, f\"Success P(complete | s, cell) | pass {ok} | local_i={local_i}\")\n",
    "    _plot(comp_map, f\"Completed-pass surface P(dest & complete | s) | pass {ok} | local_i={local_i}\")\n",
    "\n",
    "    return local_i\n",
    "\n",
    "# Run a random example from the currently loaded shard\n",
    "#infer_and_plot(local_i=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe453be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def infer_and_plot_three(local_i=None, swap_xy=False, coords_are_centers=False):\n",
    "    local_i, x_chw, dst_xy, y = sample_from_loaded_shard(local_i=local_i, swap_xy=swap_xy)\n",
    "\n",
    "    X = x_chw.unsqueeze(0).to(DEVICE)  # (1, C_dyn_full, H, W)\n",
    "\n",
    "    # ---- slice dynamic channels ----\n",
    "    X = X[:, dyn_keep_idxs]\n",
    "\n",
    "    # ---- build + slice static channels ----\n",
    "    st = static.expand_to_batch(X.size(0)).to(device=X.device, dtype=X.dtype)  # (1, C_static_full, H, W)\n",
    "    st = st[:, static_keep_idxs]\n",
    "\n",
    "    # ---- concat -> model input ----\n",
    "    X = torch.cat([X, st], dim=1)\n",
    "    X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "        dest_map, succ_map, comp_map = compute_twohead_maps(out)  # expected (H,W) each\n",
    "\n",
    "    # destination marker coords\n",
    "    dst_x = float(dst_xy[0].item())\n",
    "    dst_y = float(dst_xy[1].item())\n",
    "    if not coords_are_centers:\n",
    "        dst_x += 0.5\n",
    "        dst_y += 0.5\n",
    "\n",
    "    # approximate ball location from argmin of dist_to_ball (channel 0)\n",
    "    ball_dist = x_chw[0]  # (H,W) in your (FL,FW) convention\n",
    "    flat_idx = torch.argmin(ball_dist)\n",
    "    bx = float((flat_idx // ball_dist.shape[1]).item()) + 0.5\n",
    "    by = float((flat_idx %  ball_dist.shape[1]).item()) + 0.5\n",
    "\n",
    "    # overlay maps (channels 3/4 in your current schema)\n",
    "    in_pos  = (x_chw[3] > 0).float()\n",
    "    out_pos = (x_chw[4] > 0).float()\n",
    "\n",
    "    vis = SoccerVisualizer(pitch_length=mm.H, pitch_width=mm.W, layout=\"x_rows\")\n",
    "\n",
    "    maps = [\n",
    "        dest_map,\n",
    "        succ_map,\n",
    "        comp_map,\n",
    "    ]\n",
    "\n",
    "    for heat in maps:\n",
    "        fig, ax, artists = vis.plot_state(\n",
    "            in_possession=in_pos,\n",
    "            out_possession=out_pos,\n",
    "            heatmap=heat.detach().cpu(),     # (FL,FW)\n",
    "            add_colorbar=True,              # each figure gets its own\n",
    "            colorbar_kwargs=dict(),         # tweak if you want (ticks, format, etc.)\n",
    "            plain=True,                     # match your preference (optional)\n",
    "        )\n",
    "\n",
    "        # markers\n",
    "        ax.scatter([bx], [by], c=\"black\", s=25, marker=\"o\", zorder=25)\n",
    "        ax.scatter([dst_x], [dst_y], c=\"red\",   s=25, marker=\"o\", zorder=25)\n",
    "\n",
    "        # absolutely no titles\n",
    "        ax.set_title(\"\")\n",
    "        fig.suptitle(\"\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return local_i\n",
    "\n",
    "# Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07759881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def infer_and_plot_triptych(local_i=None, swap_xy=False, coords_are_centers=False):\n",
    "    local_i, x_chw, dst_xy, y = sample_from_loaded_shard(\n",
    "        local_i=local_i, swap_xy=swap_xy\n",
    "    )\n",
    "\n",
    "    print(y)\n",
    "\n",
    "    X = x_chw.unsqueeze(0).to(DEVICE)  # (1, C_dyn_full, H, W)\n",
    "\n",
    "    # ---- slice dynamic channels ----\n",
    "    X = X[:, dyn_keep_idxs]\n",
    "\n",
    "    # ---- build + slice static channels ----\n",
    "    st = static.expand_to_batch(X.size(0)).to(\n",
    "        device=X.device, dtype=X.dtype\n",
    "    )\n",
    "    st = st[:, static_keep_idxs]\n",
    "\n",
    "    # ---- concat -> model input ----\n",
    "    X = torch.cat([X, st], dim=1)\n",
    "    X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "        dest_map, succ_map, comp_map = compute_twohead_maps(out)\n",
    "\n",
    "    \n",
    "\n",
    "    # ---- destination marker ----\n",
    "    dst_x = float(dst_xy[0].item())\n",
    "    dst_y = float(dst_xy[1].item())\n",
    "    if not coords_are_centers:\n",
    "        dst_x += 0.5\n",
    "        dst_y += 0.5\n",
    "\n",
    "    # ---- approximate ball location ----\n",
    "    ball_dist = x_chw[0]\n",
    "    flat_idx = torch.argmin(ball_dist)\n",
    "    bx = float((flat_idx // ball_dist.shape[1]).item()) + 0.5\n",
    "    by = float((flat_idx %  ball_dist.shape[1]).item()) + 0.5\n",
    "\n",
    "    # ---- possession overlays ----\n",
    "    in_pos  = (x_chw[3] > 0).float()\n",
    "    out_pos = (x_chw[4] > 0).float()\n",
    "\n",
    "    vis = SoccerVisualizer(\n",
    "        pitch_length=mm.H,\n",
    "        pitch_width=mm.W,\n",
    "        layout=\"x_rows\",\n",
    "    )\n",
    "\n",
    "    maps = [dest_map, succ_map, comp_map]\n",
    "\n",
    "    # ---- single figure, 1x3 ----\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 3, figsize=(18, 6), constrained_layout=True\n",
    "    )\n",
    "\n",
    "    for ax, heat in zip(axes, maps):\n",
    "        vis.plot_state(\n",
    "            in_possession=in_pos,\n",
    "            out_possession=out_pos,\n",
    "            heatmap=heat.detach().cpu(),\n",
    "            ax=ax,\n",
    "            add_colorbar=True,      # colorbar per subplot\n",
    "            plain=True,\n",
    "        )\n",
    "\n",
    "        ax.scatter([bx], [by], c=\"black\", s=25, zorder=25)\n",
    "        ax.scatter([dst_x], [dst_y], c=\"red\", s=25, zorder=25)\n",
    "\n",
    "        # absolutely no titles\n",
    "        ax.set_title(\"\")\n",
    "\n",
    "    fig.suptitle(\"\")  # explicitly blank\n",
    "    plt.show()\n",
    "\n",
    "    return local_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infer_and_plot_triptych(3151)\n",
    "infer_and_plot_triptych(6801)\n",
    "infer_and_plot_triptych(481)\n",
    "infer_and_plot_triptych(555)\n",
    "infer_and_plot_triptych(1348)\n",
    "infer_and_plot_triptych(3151)\n",
    "infer_and_plot_triptych(4657)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e461c87",
   "metadata": {},
   "source": [
    "Validation example 885 from shard 0, 762 shard 1, 6801 shard 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
